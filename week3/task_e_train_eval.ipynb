{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/georg/projects/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/georg/projects/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from src.model import TripletNetwork, FasterRCNNEmbedder\n",
    "from src.data import *\n",
    "from src.transforms import albumentations_transform\n",
    "\n",
    "from torch.nn import TripletMarginLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\n",
    "\n",
    "# Initialize feature extractor, model, loss, optimizer, lr_scheduler\n",
    "\n",
    "model = FasterRCNNEmbedder()\n",
    "loss = TripletMarginLoss(margin=1.0, p=2)\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "lr_sceduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0.0001, last_epoch=-1)\n",
    "\n",
    "# initialize TripletNetwork for training\n",
    "network = TripletNetwork(model,\n",
    "                          loss,\n",
    "                          optimizer,\n",
    "                          lr_sceduler)\n",
    "\n",
    "# initialize datamodule\n",
    "\n",
    "dm = TripletDataModule(data_dir='/home/georg/projects/university/C5/task3/dataset/COCO',\n",
    "                          json_file='/home/georg/projects/university/C5/task3/dataset/COCO/mcv_image_retrieval_annotations.json',\n",
    "                          batch_size=96,\n",
    "                          #transforms=albumentations_transform(),\n",
    "                          num_workers=16,\n",
    "                          dims=(224, 224))\n",
    "\n",
    "# Initialize callbacks \n",
    "checkpointer = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", save_top_k=1, mode=\"min\", save_weights_only=True)\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "logger = CSVLogger(\"logs\", name=\"TripletNetworkCSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | FasterRCNNEmbedder | 44.8 M\n",
      "1 | criterion | TripletMarginLoss  | 0     \n",
      "-------------------------------------------------\n",
      "44.5 M    Trainable params\n",
      "225 K     Non-trainable params\n",
      "44.8 M    Total params\n",
      "179.056   Total estimated model params size (MB)\n",
      "Preparing train data: 100%|██████████| 80/80 [01:06<00:00,  1.21it/s]\n",
      "Preparing val data: 100%|██████████| 80/80 [00:00<00:00, 7641.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 855/855 [07:46<00:00,  1.83it/s, v_num=19, train_loss_step=0.195, val_loss_step=0.951, val_loss_epoch=0.682, train_loss_epoch=0.200] \n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, \n",
    "                    devices=1,\n",
    "                    accelerator='gpu',\n",
    "                    callbacks=[checkpointer, early_stopper],\n",
    "                    logger=logger,\n",
    "                    num_sanity_val_steps=0) \n",
    "trainer.fit(network, dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions to order the data \n",
    "\n",
    "def get_img_file_name(img_id, set):\n",
    "    return 'COCO_{}2014_{:012d}.jpg'.format(set, img_id)\n",
    "\n",
    "def prepare_data(json_file, mode):\n",
    "        with open(json_file, 'r') as file:\n",
    "            # Load the JSON data\n",
    "            data = json.load(file)[mode]\n",
    "        print(f'Loaded {len(data)} classes from {json_file}')\n",
    "        img_ids = []\n",
    "        labels = []\n",
    "        # loop over classes \n",
    "        for key in tqdm(data.keys(), desc=f'Preparing {mode} data'):\n",
    "            class_ = key\n",
    "            images_with_class = data[key]\n",
    "            # loop over images with the class\n",
    "            for image_id in images_with_class:\n",
    "                # if it's a new image, add it to the list of images and create a label list for it\n",
    "                if image_id not in img_ids:\n",
    "                    img_ids.append(image_id)\n",
    "                    labels.append([])\n",
    "            # loop over images and add the class to the label list if it's in the list of images\n",
    "            for i, img_id in enumerate(img_ids):\n",
    "                if img_id in images_with_class:\n",
    "                    labels[i].append(int(class_))\n",
    "\n",
    "        data_split = 'train' if mode in ['train', 'database'] else 'val'\n",
    "\n",
    "        img_files = [get_img_file_name(img_id, data_split) for img_id in img_ids]\n",
    "        return img_files, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "#load model from checkpoint and set to eval mode\n",
    "model.load_state_dict(torch.load('/home/georg/projects/university/C5/task3/task_3e/logs/TripletNetworkCSV/version_19/checkpoints/epoch=8-step=7695.ckpt'), strict=False)\n",
    "model.eval()\n",
    "\n",
    "# specify json file path\n",
    "data_json = '/home/georg/projects/university/C5/task3/dataset/COCO/mcv_image_retrieval_annotations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 classes from /home/georg/projects/university/C5/task3/dataset/COCO/mcv_image_retrieval_annotations.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing database data: 100%|██████████| 80/80 [00:00<00:00, 3512.41it/s]\n",
      "  0%|          | 0/1959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1959/1959 [01:26<00:00, 22.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "from PIL import Image\n",
    "from src.transforms import preprocess\n",
    "import numpy as np\n",
    "\n",
    "# define helper functions to extract embeddings from images using the model\n",
    "def extract_embeddings(img_files, imgs_path, model):\n",
    "    embeddings = []\n",
    "    for img_file in tqdm(img_files):\n",
    "        img_path = os.path.join(imgs_path, img_file)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = preprocess([224,224])(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        pred = model(image)\n",
    "        embeddings.append(pred.squeeze(0).cpu().detach().numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "# extract embeddings from the training images\n",
    "train_imgs_path = '/home/georg/projects/university/C5/task3/dataset/COCO/train2014'\n",
    "train_img_files, train_labels = prepare_data(json_file=data_json, mode='database')\n",
    "train_embeddings = extract_embeddings(train_img_files, train_imgs_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1959, 1024)\n",
      "1959\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS index and add the training embeddings to it\n",
    "import faiss  \n",
    "             \n",
    "index = faiss.IndexFlatL2(1024)   # build the index, d=size of vectors \n",
    "faiss.normalize_L2(train_embeddings)\n",
    "print(train_embeddings.shape)\n",
    "index.add(train_embeddings)                 # add vectors to the index\n",
    "print(index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 classes from /home/georg/projects/university/C5/task3/dataset/COCO/mcv_image_retrieval_annotations.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing test data:   0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing test data: 100%|██████████| 80/80 [00:00<00:00, 4848.49it/s]\n",
      "100%|██████████| 1917/1917 [01:21<00:00, 23.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  25   26   47   43   90]\n",
      " [1125   38 1118 1117 1122]\n",
      " [ 386  836  777  371  778]\n",
      " ...\n",
      " [ 400 1484 1535 1374 1722]\n",
      " [ 403 1656 1281 1892  670]\n",
      " [ 854 1506 1079  570  443]]\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings from the test/val images (can be configured using 'mode')\n",
    "\n",
    "val_imgs_path = '/home/georg/projects/university/C5/task3/dataset/COCO/val2014'\n",
    "val_img_files, val_labels = prepare_data(json_file=data_json, mode='test')\n",
    "val_embeddings = extract_embeddings(val_img_files, val_imgs_path, model)\n",
    "\n",
    "# Search for similar vectors k in the FAISS index\n",
    "k = 5                       # we want 4 similar vectors\n",
    "D, I = index.search(val_embeddings, k)     # actual search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2465753424657534, \n",
      "Recall: 0.2398609501738123, \n",
      "F1: 0.2431718061674009, \n",
      "Accuracy: 0.25508607198748046\n",
      "Average precision: 0.06769882984041536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Calculate precision, recall, f1, accuracy, mAP @k=1\n",
    "targets = val_labels\n",
    "preds = []\n",
    "\n",
    "preds = [train_labels[i[0]] for i in I]\n",
    "\n",
    "targets = [[1 if i in target else 0 for i in range(80)] for target in targets]\n",
    "preds = [[1 if i in pred else 0 for i in range(80)] for pred in preds]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(targets, preds, average='micro')\n",
    "accuracy = accuracy_score(targets, preds)\n",
    "print(f'Precision: {precision}, \\nRecall: {recall}, \\nF1: {f1}, \\nAccuracy: {accuracy}')\n",
    "\n",
    "# get mean average precision\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(targets, preds, average='micro')\n",
    "print(f'Average precision: {average_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.13432369038311182, \n",
      "Recall: 0.4976825028968714, \n",
      "Accuracy: 0.048513302034428794, \n",
      "F1: 0.21155030168698438\n",
      "Average precision: 0.07250391506044937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "# Calculate precision, recall, f1, accuracy, mAP @k=5\n",
    "\n",
    "preds = []\n",
    "targets = []\n",
    "def get_predicted_classes(indices):\n",
    "    classes = []\n",
    "    for index in indices:\n",
    "        classes.extend(train_labels[index])\n",
    "    classes = list(set(classes))\n",
    "    return classes\n",
    "\n",
    "for pred, target in zip(I, val_labels):\n",
    "    predicted_classes = get_predicted_classes(pred)\n",
    "    target_classes = target\n",
    "    predicted_classes = [1 if i in predicted_classes else 0 for i in range(80)]\n",
    "    target_classes = [1 if i in target_classes else 0 for i in range(80)]\n",
    "    preds.append(predicted_classes)\n",
    "    targets.append(target_classes)\n",
    "    \n",
    "\n",
    "precision = precision_score(targets, preds, average='micro' )\n",
    "recall = recall_score(targets, preds, average='micro')\n",
    "accuracy = accuracy_score(targets, preds)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(f'Precision: {precision}, \\nRecall: {recall}, \\nAccuracy: {accuracy}, \\nF1: {f1}')\n",
    "average_precision = average_precision_score(targets, preds, average='micro')\n",
    "print(f'Average precision: {average_precision}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
